{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 다회용기 분류 모델 학습\n\n## 목표\n일회용기 vs 다회용기를 구분하는 이진 분류 모델 학습\n\n## 모델\n- **백본**: ResNet50 (ImageNet 사전학습)\n- **헤드**: 2-class 분류기\n- **출력**: is_reusable (bool), confidence (float)\n\n## 데이터 구조 (새로운 구조)\n```\ndataset_output/reusable/\n├── reusable/     # 다회용기 이미지 (container 영역으로 크롭됨)\n├── disposable/   # 일회용기 이미지 (container 영역으로 크롭됨)\n└── unclear/      # 불분명한 이미지 (학습에서 제외)\n```\n\n**참고**: 데이터는 Label Studio에서 export 후 `convert_labelstudio_to_dataset.py` 스크립트로 생성됨"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 하이퍼파라미터\nBATCH_SIZE = 32\nEPOCHS = 20\nLEARNING_RATE = 0.001\nIMG_SIZE = 224\nNUM_CLASSES = 2  # reusable, disposable\n\n# 경로 (새로운 데이터셋 구조)\nDATA_DIR = '../dataset_output/reusable'  # Label Studio에서 변환된 데이터\nMODEL_SAVE_PATH = '../models/weights/reusable_classifier.pth'\n\n# Train/Val 분할 비율\nTRAIN_SPLIT = 0.8\n\n# 클래스 이름\nCLASS_NAMES = ['disposable', 'reusable']\n\nprint(f\"Dataset directory: {DATA_DIR}\")\nprint(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 및 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 Transform (데이터 증강)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet 통계\n",
    "])\n",
    "\n",
    "# 검증용 Transform (증강 없음)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.model_selection import train_test_split\n\nclass ReusableDataset(Dataset):\n    \"\"\"다회용기/일회용기 데이터셋 (크롭된 container 이미지)\"\"\"\n    \n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n        \n        print(f\"Loaded {len(self.image_paths)} images\")\n        unique, counts = np.unique(labels, return_counts=True)\n        for cls, count in zip(unique, counts):\n            print(f\"  - {CLASS_NAMES[cls]}: {count}\")\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        \n        # 이미지 로딩\n        image = Image.open(img_path).convert('RGB')\n        \n        # Transform 적용\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\ndef load_dataset_from_directory(data_dir, class_names):\n    \"\"\"디렉토리에서 데이터셋 로드 및 Train/Val 분할\"\"\"\n    all_images = []\n    all_labels = []\n    \n    for class_idx, class_name in enumerate(class_names):\n        class_dir = os.path.join(data_dir, class_name)\n        if not os.path.exists(class_dir):\n            print(f\"Warning: {class_dir} not found, skipping...\")\n            continue\n        \n        for img_name in os.listdir(class_dir):\n            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                img_path = os.path.join(class_dir, img_name)\n                all_images.append(img_path)\n                all_labels.append(class_idx)\n    \n    print(f\"\\nTotal images loaded: {len(all_images)}\")\n    print(f\"Class distribution:\")\n    unique, counts = np.unique(all_labels, return_counts=True)\n    for cls, count in zip(unique, counts):\n        print(f\"  - {class_names[cls]}: {count} ({count/len(all_labels)*100:.1f}%)\")\n    \n    # Train/Val 분할 (stratified)\n    train_images, val_images, train_labels, val_labels = train_test_split(\n        all_images, all_labels, \n        test_size=1-TRAIN_SPLIT, \n        stratify=all_labels,\n        random_state=42\n    )\n    \n    print(f\"\\nSplit: {len(train_images)} train, {len(val_images)} val\")\n    \n    return train_images, val_images, train_labels, val_labels"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 로드 및 분할\ntrain_images, val_images, train_labels, val_labels = load_dataset_from_directory(DATA_DIR, CLASS_NAMES)\n\n# 데이터셋 생성\ntrain_dataset = ReusableDataset(train_images, train_labels, transform=train_transform)\nval_dataset = ReusableDataset(val_images, val_labels, transform=val_transform)\n\n# 데이터 로더 생성\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n\nprint(f\"\\nTrain batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 샘플 이미지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 이미지 확인\n",
    "def show_samples(loader, num_samples=8):\n",
    "    images, labels = next(iter(loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        # Denormalize\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(CLASS_NAMES[labels[i]])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReusableClassifier(nn.Module):\n",
    "    \"\"\"ResNet50 기반 다회용기 분류기\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(ReusableClassifier, self).__init__()\n",
    "        \n",
    "        # ResNet50 백본 (ImageNet 사전학습)\n",
    "        self.backbone = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # 분류 헤드 교체\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = ReusableClassifier(num_classes=NUM_CLASSES, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 손실 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 (Cross Entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 학습률 스케줄러 (ReduceLROnPlateau)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 및 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"1 에폭 학습\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"검증\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 히스토리\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 학습\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # 검증\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 히스토리 저장\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # 학습률 스케줄러\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 최고 모델 저장\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"✓ Best model saved (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training completed! Best Val Acc: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습 곡선 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy\n",
    "ax2.plot(history['train_acc'], label='Train Acc')\n",
    "ax2.plot(history['val_acc'], label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 모델 로드\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "# 검증 세트 평가\n",
    "val_loss, val_acc, preds, labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 추론 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, transform, device):\n",
    "    \"\"\"단일 이미지 예측\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 이미지 로딩 및 전처리\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    is_reusable = predicted.item() == 1\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    return {\n",
    "        'is_reusable': is_reusable,\n",
    "        'confidence': confidence_score,\n",
    "        'class': CLASS_NAMES[predicted.item()],\n",
    "        'probabilities': probabilities.cpu().numpy()[0]\n",
    "    }\n",
    "\n",
    "def visualize_prediction(image_path, result):\n",
    "    \"\"\"예측 결과 시각화\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # 이미지\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {result['class']}\\nConfidence: {result['confidence']*100:.1f}%\")\n",
    "    \n",
    "    # 확률 분포\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(CLASS_NAMES, result['probabilities'])\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Class Probabilities')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 테스트 이미지로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 검증 세트에서 랜덤 샘플 선택\nimport random\n\n# 랜덤 샘플 선택\ntest_image_path = random.choice(val_images)\n\n# 예측\nresult = predict_image(model, test_image_path, val_transform, device)\n\n# 결과 출력\nprint(f\"Image: {os.path.basename(test_image_path)}\")\nprint(f\"Is Reusable: {result['is_reusable']}\")\nprint(f\"Confidence: {result['confidence']*100:.2f}%\")\nprint(f\"Class: {result['class']}\")\nprint(f\"Probabilities: Disposable={result['probabilities'][0]:.3f}, Reusable={result['probabilities'][1]:.3f}\")\n\n# 시각화\nvisualize_prediction(test_image_path, result)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 모델 저장 (ONNX 포맷, 선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX로 변환 (추론 최적화용)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "onnx_path = MODEL_SAVE_PATH.replace('.pth', '.onnx')\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"Model exported to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### 학습된 모델\n",
    "- **모델 파일**: `../models/weights/classifier.pth`\n",
    "- **최고 검증 정확도**: {best_val_acc:.2f}%\n",
    "\n",
    "### 다음 단계\n",
    "1. FastAPI 서버에 모델 통합\n",
    "2. 실전 데이터로 추가 테스트\n",
    "3. 오분류 케이스 분석 및 데이터 보강"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}