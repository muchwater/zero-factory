{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 음료 검증 모델 학습\n\n## 목표\n다회용기에 음료가 담겨있는지 확인하는 경량 이진 분류 모델\n\n## 모델\n- **백본**: MobileNetV3-Small (경량화)\n- **헤드**: 3-class 분류기 (with_beverage, empty, unclear)\n- **출력**: has_beverage (bool), confidence (float)\n- **목표 추론 속도**: < 100ms\n\n## 데이터 구조 (새로운 구조)\n```\ndataset_output/beverage/\n├── with_beverage/  # 음료 있음 (container 영역으로 크롭됨)\n├── empty/          # 빈 용기 (container 영역으로 크롭됨)\n└── unclear/        # 불분명 (학습에 포함 가능, 선택적)\n```\n\n**참고**: 데이터는 Label Studio에서 export 후 `convert_labelstudio_to_dataset.py` 스크립트로 생성됨"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 하이퍼파라미터\nBATCH_SIZE = 32\nEPOCHS = 15\nLEARNING_RATE = 0.001\nIMG_SIZE = 224\n\n# 경로 (새로운 데이터셋 구조)\nDATA_DIR = '../dataset_output/beverage'  # Label Studio에서 변환된 데이터\nMODEL_SAVE_PATH = '../models/weights/beverage_detector.pth'\n\n# Train/Val 분할 비율\nTRAIN_SPLIT = 0.8\n\n# 클래스 설정 (unclear 포함 여부 선택)\nINCLUDE_UNCLEAR = True  # unclear 클래스를 학습에 포함할지 여부\n\nif INCLUDE_UNCLEAR:\n    CLASS_NAMES = ['empty', 'with_beverage', 'unclear']\n    NUM_CLASSES = 3\nelse:\n    CLASS_NAMES = ['empty', 'with_beverage']\n    NUM_CLASSES = 2\n\nprint(f\"Dataset directory: {DATA_DIR}\")\nprint(f\"Model will be saved to: {MODEL_SAVE_PATH}\")\nprint(f\"Classes: {CLASS_NAMES} ({NUM_CLASSES} classes)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 Transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # 음료 색상 다양성\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 검증용 Transform\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.model_selection import train_test_split\n\nclass BeverageDataset(Dataset):\n    \"\"\"음료 포함 여부 데이터셋 (크롭된 container 이미지)\"\"\"\n    \n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n        \n        print(f\"Loaded {len(self.image_paths)} images\")\n        unique, counts = np.unique(labels, return_counts=True)\n        for cls, count in zip(unique, counts):\n            print(f\"  - {CLASS_NAMES[cls]}: {count}\")\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        \n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\ndef load_dataset_from_directory(data_dir, class_names):\n    \"\"\"디렉토리에서 데이터셋 로드 및 Train/Val 분할\"\"\"\n    all_images = []\n    all_labels = []\n    \n    for class_idx, class_name in enumerate(class_names):\n        class_dir = os.path.join(data_dir, class_name)\n        if not os.path.exists(class_dir):\n            print(f\"Warning: {class_dir} not found, skipping...\")\n            continue\n        \n        for img_name in os.listdir(class_dir):\n            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                img_path = os.path.join(class_dir, img_name)\n                all_images.append(img_path)\n                all_labels.append(class_idx)\n    \n    print(f\"\\nTotal images loaded: {len(all_images)}\")\n    print(f\"Class distribution:\")\n    unique, counts = np.unique(all_labels, return_counts=True)\n    for cls, count in zip(unique, counts):\n        print(f\"  - {class_names[cls]}: {count} ({count/len(all_labels)*100:.1f}%)\")\n    \n    # Train/Val 분할 (stratified)\n    train_images, val_images, train_labels, val_labels = train_test_split(\n        all_images, all_labels, \n        test_size=1-TRAIN_SPLIT, \n        stratify=all_labels,\n        random_state=42\n    )\n    \n    print(f\"\\nSplit: {len(train_images)} train, {len(val_images)} val\")\n    \n    return train_images, val_images, train_labels, val_labels"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 로드 및 분할\ntrain_images, val_images, train_labels, val_labels = load_dataset_from_directory(DATA_DIR, CLASS_NAMES)\n\n# 데이터셋 생성\ntrain_dataset = BeverageDataset(train_images, train_labels, transform=train_transform)\nval_dataset = BeverageDataset(val_images, val_labels, transform=val_transform)\n\n# 데이터 로더\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n\nprint(f\"\\nTrain batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 샘플 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(loader, num_samples=8):\n",
    "    images, labels = next(iter(loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(CLASS_NAMES[labels[i]])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 경량 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeverageDetector(nn.Module):\n",
    "    \"\"\"MobileNetV3-Small 기반 음료 검증 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(BeverageDetector, self).__init__()\n",
    "        \n",
    "        # MobileNetV3-Small 백본 (경량화)\n",
    "        self.backbone = models.mobilenet_v3_small(pretrained=pretrained)\n",
    "        \n",
    "        # 분류 헤드 교체\n",
    "        num_features = self.backbone.classifier[0].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.Hardswish(),  # MobileNetV3에 최적화된 활성화 함수\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = BeverageDetector(num_classes=NUM_CLASSES, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\n✓ Lightweight model for fast inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 손실 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 및 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "    \n",
    "    return running_loss / len(loader), 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100 * accuracy_score(all_labels, all_preds), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"✓ Best model saved (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training completed! Best Val Acc: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Curve')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train Acc')\n",
    "ax2.plot(history['val_acc'], label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 모델 로드\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "val_loss, val_acc, preds, labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 추론 속도 벤치마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 속도 측정\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "# 벤치마크\n",
    "num_runs = 100\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_runs):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()\n",
    "avg_time = (end_time - start_time) / num_runs * 1000  # ms\n",
    "\n",
    "print(f\"Inference Speed:\")\n",
    "print(f\"  Average time: {avg_time:.2f} ms\")\n",
    "print(f\"  Throughput: {1000/avg_time:.1f} images/sec\")\n",
    "print(f\"\\n{'✓' if avg_time < 100 else '✗'} Target < 100ms: {'Achieved' if avg_time < 100 else 'Not achieved'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 추론 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def detect_beverage(model, image_path, transform, device):\n    \"\"\"\n    이미지에서 음료 포함 여부 검증\n    \n    Args:\n        model: 학습된 모델\n        image_path: 이미지 경로\n        transform: 전처리 transform\n        device: 디바이스\n    \n    Returns:\n        dict: {'has_beverage': bool, 'confidence': float}\n    \"\"\"\n    model.eval()\n    \n    image = Image.open(image_path).convert('RGB')\n    image_tensor = transform(image).unsqueeze(0).to(device)\n    \n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        confidence, predicted = torch.max(probabilities, 1)\n    \n    # with_beverage 클래스 확인 (클래스 인덱스가 1)\n    has_beverage = CLASS_NAMES[predicted.item()] == 'with_beverage'\n    confidence_score = confidence.item()\n    \n    return {\n        'has_beverage': has_beverage,\n        'confidence': confidence_score,\n        'class': CLASS_NAMES[predicted.item()],\n        'probabilities': probabilities.cpu().numpy()[0]\n    }\n\ndef visualize_detection(image_path, result):\n    image = Image.open(image_path)\n    \n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.axis('off')\n    title_color = 'green' if result['has_beverage'] else 'red'\n    plt.title(f\"Detection: {result['class']}\\nConfidence: {result['confidence']*100:.1f}%\", \n              color=title_color, fontsize=14, fontweight='bold')\n    \n    plt.subplot(1, 2, 2)\n    colors = ['lightcoral' if c == 'empty' else 'lightgreen' if c == 'with_beverage' else 'lightgray' \n              for c in CLASS_NAMES]\n    plt.bar(CLASS_NAMES, result['probabilities'], color=colors)\n    plt.ylabel('Probability')\n    plt.title('Class Probabilities')\n    plt.ylim(0, 1)\n    plt.xticks(rotation=15)\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 테스트 이미지로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 검증 세트에서 랜덤 샘플 선택\nimport random\n\n# 각 클래스별로 샘플 선택\nfor class_idx, class_name in enumerate(CLASS_NAMES):\n    # 해당 클래스의 이미지 찾기\n    class_images = [img for img, label in zip(val_images, val_labels) if label == class_idx]\n    \n    if class_images:\n        test_image_path = random.choice(class_images)\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Testing: {class_name}\")\n        print(f\"Image: {os.path.basename(test_image_path)}\")\n        print(f\"{'='*60}\")\n        \n        result = detect_beverage(model, test_image_path, val_transform, device)\n        \n        print(f\"Predicted class: {result['class']}\")\n        print(f\"Has beverage: {result['has_beverage']}\")\n        print(f\"Confidence: {result['confidence']*100:.2f}%\")\n        print(f\"Probabilities:\")\n        for cls, prob in zip(CLASS_NAMES, result['probabilities']):\n            print(f\"  - {cls}: {prob:.3f}\")\n        \n        visualize_detection(test_image_path, result)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 모델 최적화 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 (INT8) - 추론 속도 더 향상\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# 양자화 모델 저장\n",
    "quantized_path = MODEL_SAVE_PATH.replace('.pth', '_quantized.pth')\n",
    "torch.save(model_quantized.state_dict(), quantized_path)\n",
    "\n",
    "print(f\"Quantized model saved: {quantized_path}\")\n",
    "\n",
    "# 크기 비교\n",
    "original_size = os.path.getsize(MODEL_SAVE_PATH) / (1024 * 1024)  # MB\n",
    "quantized_size = os.path.getsize(quantized_path) / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nModel size:\")\n",
    "print(f\"  Original: {original_size:.2f} MB\")\n",
    "print(f\"  Quantized: {quantized_size:.2f} MB\")\n",
    "print(f\"  Reduction: {(1 - quantized_size/original_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. ONNX 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX 변환 (배포용)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "onnx_path = MODEL_SAVE_PATH.replace('.pth', '.onnx')\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"Model exported to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. 실전 시나리오 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실전 시나리오: 사용 인증 워크플로우\n",
    "def verify_usage(image_path, model, transform, device, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    사용 인증: 음료가 담겨있으면 통과\n",
    "    \n",
    "    Args:\n",
    "        image_path: 사용 인증 이미지\n",
    "        model: 학습된 모델\n",
    "        transform: 전처리\n",
    "        device: 디바이스\n",
    "        confidence_threshold: 신뢰도 임계값\n",
    "    \n",
    "    Returns:\n",
    "        dict: 검증 결과\n",
    "    \"\"\"\n",
    "    result = detect_beverage(model, image_path, transform, device)\n",
    "    \n",
    "    # 검증 로직\n",
    "    is_valid = result['has_beverage'] and result['confidence'] >= confidence_threshold\n",
    "    \n",
    "    return {\n",
    "        'is_valid': is_valid,\n",
    "        'has_beverage': result['has_beverage'],\n",
    "        'confidence': result['confidence'],\n",
    "        'message': 'OK' if is_valid else 'Beverage not detected or low confidence'\n",
    "    }\n",
    "\n",
    "# 테스트\n",
    "test_cases = [\n",
    "    ('../data/usage_test/coffee_tumbler.jpg', '커피 담긴 텀블러'),\n",
    "    ('../data/usage_test/empty_tumbler.jpg', '빈 텀블러'),\n",
    "    ('../data/usage_test/water_bottle.jpg', '물 담긴 보틀'),\n",
    "]\n",
    "\n",
    "for img_path, description in test_cases:\n",
    "    if os.path.exists(img_path):\n",
    "        result = verify_usage(img_path, model, val_transform, device)\n",
    "        print(f\"{description}:\")\n",
    "        print(f\"  Valid: {result['is_valid']}\")\n",
    "        print(f\"  Has beverage: {result['has_beverage']}\")\n",
    "        print(f\"  Confidence: {result['confidence']*100:.2f}%\")\n",
    "        print(f\"  Message: {result['message']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### 모델 성능\n",
    "- **최고 검증 정확도**: {best_val_acc:.2f}%\n",
    "- **추론 속도**: ~{avg_time:.2f}ms (목표 < 100ms)\n",
    "- **모델 크기**: ~{original_size:.2f}MB\n",
    "\n",
    "### 검증 기준\n",
    "- **음료 있음** → ✅ 통과\n",
    "- **음료 없음** → ❌ 거부\n",
    "- **신뢰도 임계값**: 0.7 (조정 가능)\n",
    "\n",
    "### 다음 단계\n",
    "1. FastAPI 서버에 모델 통합\n",
    "2. 실전 데이터로 추가 테스트\n",
    "3. 오분류 케이스 분석 및 개선\n",
    "4. 모델 최적화 (양자화, ONNX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}