{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음료 검증 모델 학습\n",
    "\n",
    "## 목표\n",
    "다회용기에 음료가 담겨있는지 확인하는 경량 이진 분류 모델\n",
    "\n",
    "## 모델\n",
    "- **백본**: MobileNetV3-Small (경량화)\n",
    "- **헤드**: 2-class 분류기\n",
    "- **출력**: has_beverage (bool), confidence (float)\n",
    "- **목표 추론 속도**: < 100ms\n",
    "\n",
    "## 데이터 구조\n",
    "```\n",
    "data/beverage_detection/\n",
    "├── train/\n",
    "│   ├── with_beverage/    # 음료 있음\n",
    "│   └── without_beverage/ # 빈 용기\n",
    "└── val/\n",
    "    ├── with_beverage/\n",
    "    └── without_beverage/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 2  # with_beverage, without_beverage\n",
    "\n",
    "# 경로\n",
    "TRAIN_DIR = '../data/beverage_detection/train'\n",
    "VAL_DIR = '../data/beverage_detection/val'\n",
    "MODEL_SAVE_PATH = '../models/weights/beverage_detector.pth'\n",
    "\n",
    "# 클래스 이름\n",
    "CLASS_NAMES = ['without_beverage', 'with_beverage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 Transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # 음료 색상 다양성\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 검증용 Transform\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeverageDataset(Dataset):\n",
    "    \"\"\"음료 포함 여부 데이터셋\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 데이터 로딩\n",
    "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: {class_dir} not found\")\n",
    "                continue\n",
    "                \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(class_idx)\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} images from {root_dir}\")\n",
    "        print(f\"  - Without beverage: {self.labels.count(0)}\")\n",
    "        print(f\"  - With beverage: {self.labels.count(1)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "train_dataset = BeverageDataset(TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = BeverageDataset(VAL_DIR, transform=val_transform)\n",
    "\n",
    "# 데이터 로더\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 샘플 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(loader, num_samples=8):\n",
    "    images, labels = next(iter(loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(CLASS_NAMES[labels[i]])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 경량 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeverageDetector(nn.Module):\n",
    "    \"\"\"MobileNetV3-Small 기반 음료 검증 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(BeverageDetector, self).__init__()\n",
    "        \n",
    "        # MobileNetV3-Small 백본 (경량화)\n",
    "        self.backbone = models.mobilenet_v3_small(pretrained=pretrained)\n",
    "        \n",
    "        # 분류 헤드 교체\n",
    "        num_features = self.backbone.classifier[0].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.Hardswish(),  # MobileNetV3에 최적화된 활성화 함수\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = BeverageDetector(num_classes=NUM_CLASSES, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\n✓ Lightweight model for fast inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 손실 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 및 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "    \n",
    "    return running_loss / len(loader), 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100 * accuracy_score(all_labels, all_preds), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"✓ Best model saved (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Training completed! Best Val Acc: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Curve')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history['train_acc'], label='Train Acc')\n",
    "ax2.plot(history['val_acc'], label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 모델 로드\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "val_loss, val_acc, preds, labels = validate(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 추론 속도 벤치마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 속도 측정\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "# 벤치마크\n",
    "num_runs = 100\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_runs):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()\n",
    "avg_time = (end_time - start_time) / num_runs * 1000  # ms\n",
    "\n",
    "print(f\"Inference Speed:\")\n",
    "print(f\"  Average time: {avg_time:.2f} ms\")\n",
    "print(f\"  Throughput: {1000/avg_time:.1f} images/sec\")\n",
    "print(f\"\\n{'✓' if avg_time < 100 else '✗'} Target < 100ms: {'Achieved' if avg_time < 100 else 'Not achieved'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 추론 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_beverage(model, image_path, transform, device):\n",
    "    \"\"\"\n",
    "    이미지에서 음료 포함 여부 검증\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 모델\n",
    "        image_path: 이미지 경로\n",
    "        transform: 전처리 transform\n",
    "        device: 디바이스\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'has_beverage': bool, 'confidence': float}\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    has_beverage = predicted.item() == 1\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    return {\n",
    "        'has_beverage': has_beverage,\n",
    "        'confidence': confidence_score,\n",
    "        'class': CLASS_NAMES[predicted.item()],\n",
    "        'probabilities': probabilities.cpu().numpy()[0]\n",
    "    }\n",
    "\n",
    "def visualize_detection(image_path, result):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detection: {result['class']}\\nConfidence: {result['confidence']*100:.1f}%\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(CLASS_NAMES, result['probabilities'])\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Class Probabilities')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 테스트 이미지로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 이미지 경로\n",
    "test_image_with = '../data/beverage_detection/val/with_beverage/test1.jpg'\n",
    "test_image_without = '../data/beverage_detection/val/without_beverage/test2.jpg'\n",
    "\n",
    "# 음료 있음 테스트\n",
    "if os.path.exists(test_image_with):\n",
    "    result = detect_beverage(model, test_image_with, val_transform, device)\n",
    "    print(f\"Test 1: {result['class']} (confidence: {result['confidence']*100:.2f}%)\")\n",
    "    visualize_detection(test_image_with, result)\n",
    "\n",
    "# 음료 없음 테스트\n",
    "if os.path.exists(test_image_without):\n",
    "    result = detect_beverage(model, test_image_without, val_transform, device)\n",
    "    print(f\"Test 2: {result['class']} (confidence: {result['confidence']*100:.2f}%)\")\n",
    "    visualize_detection(test_image_without, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 모델 최적화 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 (INT8) - 추론 속도 더 향상\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# 양자화 모델 저장\n",
    "quantized_path = MODEL_SAVE_PATH.replace('.pth', '_quantized.pth')\n",
    "torch.save(model_quantized.state_dict(), quantized_path)\n",
    "\n",
    "print(f\"Quantized model saved: {quantized_path}\")\n",
    "\n",
    "# 크기 비교\n",
    "original_size = os.path.getsize(MODEL_SAVE_PATH) / (1024 * 1024)  # MB\n",
    "quantized_size = os.path.getsize(quantized_path) / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nModel size:\")\n",
    "print(f\"  Original: {original_size:.2f} MB\")\n",
    "print(f\"  Quantized: {quantized_size:.2f} MB\")\n",
    "print(f\"  Reduction: {(1 - quantized_size/original_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. ONNX 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX 변환 (배포용)\n",
    "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "onnx_path = MODEL_SAVE_PATH.replace('.pth', '.onnx')\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"Model exported to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. 실전 시나리오 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실전 시나리오: 사용 인증 워크플로우\n",
    "def verify_usage(image_path, model, transform, device, confidence_threshold=0.7):\n",
    "    \"\"\"\n",
    "    사용 인증: 음료가 담겨있으면 통과\n",
    "    \n",
    "    Args:\n",
    "        image_path: 사용 인증 이미지\n",
    "        model: 학습된 모델\n",
    "        transform: 전처리\n",
    "        device: 디바이스\n",
    "        confidence_threshold: 신뢰도 임계값\n",
    "    \n",
    "    Returns:\n",
    "        dict: 검증 결과\n",
    "    \"\"\"\n",
    "    result = detect_beverage(model, image_path, transform, device)\n",
    "    \n",
    "    # 검증 로직\n",
    "    is_valid = result['has_beverage'] and result['confidence'] >= confidence_threshold\n",
    "    \n",
    "    return {\n",
    "        'is_valid': is_valid,\n",
    "        'has_beverage': result['has_beverage'],\n",
    "        'confidence': result['confidence'],\n",
    "        'message': 'OK' if is_valid else 'Beverage not detected or low confidence'\n",
    "    }\n",
    "\n",
    "# 테스트\n",
    "test_cases = [\n",
    "    ('../data/usage_test/coffee_tumbler.jpg', '커피 담긴 텀블러'),\n",
    "    ('../data/usage_test/empty_tumbler.jpg', '빈 텀블러'),\n",
    "    ('../data/usage_test/water_bottle.jpg', '물 담긴 보틀'),\n",
    "]\n",
    "\n",
    "for img_path, description in test_cases:\n",
    "    if os.path.exists(img_path):\n",
    "        result = verify_usage(img_path, model, val_transform, device)\n",
    "        print(f\"{description}:\")\n",
    "        print(f\"  Valid: {result['is_valid']}\")\n",
    "        print(f\"  Has beverage: {result['has_beverage']}\")\n",
    "        print(f\"  Confidence: {result['confidence']*100:.2f}%\")\n",
    "        print(f\"  Message: {result['message']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "### 모델 성능\n",
    "- **최고 검증 정확도**: {best_val_acc:.2f}%\n",
    "- **추론 속도**: ~{avg_time:.2f}ms (목표 < 100ms)\n",
    "- **모델 크기**: ~{original_size:.2f}MB\n",
    "\n",
    "### 검증 기준\n",
    "- **음료 있음** → ✅ 통과\n",
    "- **음료 없음** → ❌ 거부\n",
    "- **신뢰도 임계값**: 0.7 (조정 가능)\n",
    "\n",
    "### 다음 단계\n",
    "1. FastAPI 서버에 모델 통합\n",
    "2. 실전 데이터로 추가 테스트\n",
    "3. 오분류 케이스 분석 및 개선\n",
    "4. 모델 최적화 (양자화, ONNX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
