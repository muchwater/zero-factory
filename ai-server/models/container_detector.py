"""
Container Detection using YOLO
Detects and crops bottle/cup containers from images
"""

import torch
from PIL import Image
import io
from ultralytics import YOLO
import numpy as np


class ContainerDetector:
    """YOLO ê¸°ë°˜ ìš©ê¸°(bottle, cup) ê°ì§€ ë° í¬ë¡­"""

    # COCO ë°ì´í„°ì…‹ì˜ ìš©ê¸° ê´€ë ¨ í´ë˜ìŠ¤ ID
    CONTAINER_CLASSES = {
        39: 'bottle',      # ë³‘
        41: 'cup',         # ì»µ
        45: 'bowl',        # ê·¸ë¦‡
        46: 'wine glass',  # ì™€ì¸ì”
        47: 'vase',        # ê½ƒë³‘
        61: 'container',   # ì„ì‹œ: YOLOê°€ ì»µì„ toiletìœ¼ë¡œ ì˜¤ì¸ì‹í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
    }

    def __init__(self, model_path: str = 'yolov8n.pt', confidence_threshold: float = 0.25, device: str = 'cuda'):
        """
        Args:
            model_path: YOLO ëª¨ë¸ ê²½ë¡œ
            confidence_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
            device: 'cuda' ë˜ëŠ” 'cpu'
        """
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.confidence_threshold = confidence_threshold

        print(f"Loading YOLO model: {model_path} on {self.device}")
        self.model = YOLO(model_path)
        print("âœ“ Container detector loaded")

    def detect_and_crop(self, image_bytes: bytes, padding_ratio: float = 0.1) -> dict:
        """
        ì´ë¯¸ì§€ì—ì„œ ìš©ê¸°ë¥¼ ê°ì§€í•˜ê³  í¬ë¡­í•©ë‹ˆë‹¤.

        Args:
            image_bytes: ì…ë ¥ ì´ë¯¸ì§€ ë°”ì´íŠ¸
            padding_ratio: bbox íŒ¨ë”© ë¹„ìœ¨

        Returns:
            dict: {
                'success': bool,
                'container_detected': bool,
                'num_containers': int,
                'cropped_image': PIL.Image or None,
                'bbox': [x1, y1, x2, y2] or None,
                'class_name': str or None,
                'confidence': float or None,
                'error': str or None
            }
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
            img_array = np.array(image)

            # YOLO ì¶”ë¡ 
            results = self.model.predict(
                img_array,
                conf=self.confidence_threshold,
                device=self.device,
                verbose=False
            )

            # ë””ë²„ê¹…: ëª¨ë“  ê²€ì¶œëœ ê°ì²´ ë¡œê¹…
            all_detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    cls_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    class_name = result.names.get(cls_id, f'class_{cls_id}')
                    all_detections.append({
                        'class_id': cls_id,
                        'class_name': class_name,
                        'confidence': confidence
                    })

            if all_detections:
                print(f"ğŸ” YOLO detected {len(all_detections)} objects: {all_detections}")
            else:
                print(f"ğŸ” YOLO detected NO objects (threshold: {self.confidence_threshold})")

            # ìš©ê¸° í´ë˜ìŠ¤ë§Œ í•„í„°ë§
            detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    cls_id = int(box.cls[0])
                    if cls_id in self.CONTAINER_CLASSES:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0])

                        detections.append({
                            'class_id': cls_id,
                            'class_name': self.CONTAINER_CLASSES[cls_id],
                            'bbox': [int(x1), int(y1), int(x2), int(y2)],
                            'confidence': confidence
                        })

            if all_detections and not detections:
                print(f"âš ï¸  Objects detected but NO bottles/cups (container classes: {self.CONTAINER_CLASSES})")
                print(f"   Detected objects: {all_detections}")
                # TODO: í–¥í›„ custom YOLO ëª¨ë¸ ì‚¬ìš© ì‹œ ì´ ì¼€ì´ìŠ¤ ì²˜ë¦¬

            # ê°ì§€ëœ ìš©ê¸°ê°€ ì—†ëŠ” ê²½ìš°
            if len(detections) == 0:
                return {
                    'success': False,
                    'container_detected': False,
                    'num_containers': 0,
                    'cropped_image': None,
                    'bbox': None,
                    'class_name': None,
                    'confidence': None,
                    'error': 'No container detected'
                }

            # 2ê°œ ì´ìƒ ê°ì§€ëœ ê²½ìš°: ê°€ì¥ ë†’ì€ í™•ì‹ ë„ë¥¼ ê°€ì§„ ê²ƒ ì„ íƒ
            if len(detections) > 1:
                detection = max(detections, key=lambda x: x['confidence'])
                print(f"âš ï¸  Multiple containers detected ({len(detections)}), selecting highest confidence: {detection['confidence']:.2f}")
            else:
                # ì •í™•íˆ 1ê°œ ê°ì§€ëœ ê²½ìš°
                detection = detections[0]
            bbox = detection['bbox']

            # Crop with padding
            cropped_image = self._crop_with_padding(image, bbox, padding_ratio)

            return {
                'success': True,
                'container_detected': True,
                'num_containers': len(detections),  # ì‹¤ì œ ê²€ì¶œëœ ì´ ê°œìˆ˜
                'cropped_image': cropped_image,
                'bbox': bbox,
                'class_name': detection['class_name'],
                'confidence': detection['confidence'],
                'error': None
            }

        except Exception as e:
            return {
                'success': False,
                'container_detected': False,
                'num_containers': 0,
                'cropped_image': None,
                'bbox': None,
                'class_name': None,
                'confidence': None,
                'error': f'Detection error: {str(e)}'
            }

    def _crop_with_padding(self, image: Image.Image, bbox: list, padding_ratio: float) -> Image.Image:
        """
        bboxë¡œ ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•©ë‹ˆë‹¤ (íŒ¨ë”© ì¶”ê°€).

        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            bbox: [x1, y1, x2, y2]
            padding_ratio: bbox í¬ê¸° ëŒ€ë¹„ íŒ¨ë”© ë¹„ìœ¨

        Returns:
            í¬ë¡­ëœ ì´ë¯¸ì§€
        """
        w, h = image.size
        x1, y1, x2, y2 = bbox

        # bbox í¬ê¸° ê³„ì‚°
        bbox_w = x2 - x1
        bbox_h = y2 - y1

        # íŒ¨ë”© ì¶”ê°€
        pad_x = int(bbox_w * padding_ratio)
        pad_y = int(bbox_h * padding_ratio)

        # ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
        x1 = max(0, x1 - pad_x)
        y1 = max(0, y1 - pad_y)
        x2 = min(w, x2 + pad_x)
        y2 = min(h, y2 + pad_y)

        # í¬ë¡­
        cropped = image.crop((x1, y1, x2, y2))
        return cropped
