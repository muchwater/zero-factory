"""
AI Model Server for Reusable Container Verification
FastAPI ì„œë²„ - ë‹¤íšŒìš©ê¸° ê²€ì¦ AI ì„œë¹„ìŠ¤
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from typing import List
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(
    title="Reusable Container AI Service",
    description="AI ê¸°ë°˜ ë‹¤íšŒìš©ê¸° ê²€ì¦ ì„œë¹„ìŠ¤",
    version="0.1.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # TODO: í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# TODO: ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
classifier = None
embedding_generator = None
beverage_detector = None


# Response Models
class ClassificationResponse(BaseModel):
    """ì¼íšŒìš©/ë‹¤íšŒìš© ë¶„ë¥˜ ì‘ë‹µ"""
    is_reusable: bool
    confidence: float
    message: str


class EmbeddingResponse(BaseModel):
    """ì„ë² ë”© ë²¡í„° ì‘ë‹µ"""
    embedding: List[float]
    dimension: int


class BeverageVerificationResponse(BaseModel):
    """ìŒë£Œ ê²€ì¦ ì‘ë‹µ"""
    has_beverage: bool
    confidence: float
    message: str


@app.on_event("startup")
async def startup_event():
    """
    ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë”©
    TODO: ì‹¤ì œ ëª¨ë¸ ë¡œë”© êµ¬í˜„
    """
    global classifier, embedding_generator, beverage_detector

    print("ğŸš€ AI Model Server Starting...")
    print(f"Device: {os.getenv('DEVICE', 'cpu')}")

    # TODO: ëª¨ë¸ ë¡œë”© êµ¬í˜„
    # from models.classifier import ReusableClassifier
    # from models.embedding import EmbeddingGenerator
    # from models.beverage_detector import BeverageDetector

    # classifier = ReusableClassifier(...)
    # embedding_generator = EmbeddingGenerator(...)
    # beverage_detector = BeverageDetector(...)

    print("âœ… Server ready (models not loaded yet - TODO)")


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "AI Model Server is running",
        "status": "healthy",
        "version": "0.1.0"
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "device": os.getenv("DEVICE", "cpu"),
        "models_loaded": {
            "classifier": classifier is not None,
            "embedding_generator": embedding_generator is not None,
            "beverage_detector": beverage_detector is not None,
        }
    }


@app.post("/classify-reusable", response_model=ClassificationResponse)
async def classify_reusable(file: UploadFile = File(...)):
    """
    ë‹¤íšŒìš©ê¸° vs ì¼íšŒìš©ê¸° ë¶„ë¥˜
    TODO: ì‹¤ì œ êµ¬í˜„
    """
    try:
        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        return ClassificationResponse(
            is_reusable=True,
            confidence=0.85,
            message="TODO: ì‹¤ì œ ëª¨ë¸ êµ¬í˜„ í•„ìš”"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/generate-embedding", response_model=EmbeddingResponse)
async def generate_embedding(file: UploadFile = File(...)):
    """
    ì´ë¯¸ì§€ ì„ë² ë”© ë²¡í„° ìƒì„± (512ì°¨ì›)
    TODO: ì‹¤ì œ êµ¬í˜„
    """
    try:
        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        dummy_embedding = [0.0] * 512
        return EmbeddingResponse(
            embedding=dummy_embedding,
            dimension=512
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/verify-beverage", response_model=BeverageVerificationResponse)
async def verify_beverage(file: UploadFile = File(...)):
    """
    ìŒë£Œ í¬í•¨ ì—¬ë¶€ ê²€ì¦
    TODO: ì‹¤ì œ êµ¬í˜„
    """
    try:
        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        return BeverageVerificationResponse(
            has_beverage=True,
            confidence=0.90,
            message="TODO: ì‹¤ì œ ëª¨ë¸ êµ¬í˜„ í•„ìš”"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True,
        log_level="info"
    )
