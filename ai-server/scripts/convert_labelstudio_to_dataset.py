#!/usr/bin/env python3
"""
Label Studio ì–´ë…¸í…Œì´ì…˜ì„ í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì‚¬ìš© (í˜„ì¬ ë””ë ‰í† ë¦¬ì— ZIP íŒŒì¼ ìƒì„±)
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images

    # ì„ë² ë”©ìš© types/ ë””ë ‰í† ë¦¬ í¬í•¨
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images --include-types

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images --output-dir ./datasets

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ëª… ì§€ì •
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images --output-dir ./datasets --output-file my_dataset.zip

    # reusable ë°ì´í„°ì…‹ë§Œ ìƒì„±
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images --task reusable

    # beverage ë°ì´í„°ì…‹ê³¼ types í¬í•¨
    python convert_labelstudio_to_dataset.py export.json --image-dir ./images --task beverage --include-types

    # ìš°ë¦¬ íŒŒì¼êµ¬ì¡°ì—ì„œ,,,
    python3 ./scripts/convert_labelstudio_to_dataset.py ./label-studio/export/project-1-at-2025-11-10-01-59-baddde76.json --image-dir ./data/raw_images/ --output-dir ./dataset_output --include-types

ì¶œë ¥ êµ¬ì¡°:
    dataset_YYYYMMDD_HHMMSS.zip
    â”œâ”€â”€ reusable/
    â”‚   â”œâ”€â”€ reusable/       # ë‹¤íšŒìš© ìš©ê¸° ì´ë¯¸ì§€
    â”‚   â”œâ”€â”€ disposable/     # ì¼íšŒìš© ìš©ê¸° ì´ë¯¸ì§€
    â”‚   â””â”€â”€ unclear/        # ë¶ˆë¶„ëª…í•œ ì´ë¯¸ì§€
    â”œâ”€â”€ beverage/
    â”‚   â”œâ”€â”€ with_beverage/  # ìŒë£Œê°€ ìˆëŠ” ì´ë¯¸ì§€
    â”‚   â”œâ”€â”€ empty/          # ë¹ˆ ìš©ê¸° ì´ë¯¸ì§€
    â”‚   â””â”€â”€ unclear/        # ë¶ˆë¶„ëª…í•œ ì´ë¯¸ì§€
    â””â”€â”€ types/              # --include-types ì‚¬ìš© ì‹œ
        â”œâ”€â”€ CUP001/         # ì»µ ì½”ë“œë³„ ë¶„ë¥˜ (ì„ë² ë”©ìš©)
        â”œâ”€â”€ CUP002/
        â””â”€â”€ ...
"""

import json
import shutil
from pathlib import Path
from urllib.parse import urlparse
import argparse
from PIL import Image
import requests
from io import BytesIO
import zipfile
from datetime import datetime
import tempfile


def parse_labelstudio_json(json_path: str, base_image_dir: str = None):
    """Label Studio JSONì„ íŒŒì‹±í•˜ê³  container bbox ì¶”ì¶œ

    Args:
        json_path: Label Studio export JSON íŒŒì¼ ê²½ë¡œ
        base_image_dir: ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬ (optional)

    Returns:
        list: íŒŒì‹±ëœ ê²°ê³¼ (container bbox í¬í•¨)
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    results = []
    stats = {
        'total': len(data),
        'no_annotation': 0,
        'no_container': 0,
        'multiple_containers': 0,
        'valid': 0
    }

    for item in data:
        if not item.get('annotations'):
            stats['no_annotation'] += 1
            continue

        # ì²« ë²ˆì§¸ ì–´ë…¸í…Œì´ì…˜ ì‚¬ìš©
        annotation = item['annotations'][0]
        result = annotation.get('result', [])

        # ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ
        image_path = item['data'].get('image', '')
        if image_path.startswith('http'):
            # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            image_filename = Path(urlparse(image_path).path).name
        else:
            image_filename = Path(image_path).name

        # Container bboxì™€ ë¼ë²¨ ì¶”ì¶œ
        labels = {}
        containers = []

        for r in result:
            if r.get('type') == 'choices':
                choice_name = r.get('from_name')
                labels[choice_name] = r['value']['choices'][0]
            elif r.get('type') == 'rectanglelabels':
                # Rectangle bbox ì¶”ì¶œ
                label_names = r['value'].get('rectanglelabels', [])
                if 'container' in label_names:
                    containers.append({
                        'x': r['value']['x'],
                        'y': r['value']['y'],
                        'width': r['value']['width'],
                        'height': r['value']['height']
                    })

        # Containerê°€ ì •í™•íˆ 1ê°œì¸ ê²½ìš°ë§Œ í¬í•¨
        if len(containers) == 0:
            stats['no_container'] += 1
            print(f"âš ï¸  Skipping {image_filename}: No container bbox")
            continue
        elif len(containers) > 1:
            stats['multiple_containers'] += 1
            print(f"âš ï¸  Skipping {image_filename}: Multiple containers ({len(containers)})")
            continue

        stats['valid'] += 1
        results.append({
            'image': image_filename,
            'image_path': image_path,
            'labels': labels,
            'container_bbox': containers[0],
            'annotation_id': annotation.get('id')
        })

    print(f"\n=== Parsing Statistics ===")
    print(f"Total: {stats['total']}")
    print(f"No annotation: {stats['no_annotation']}")
    print(f"No container: {stats['no_container']}")
    print(f"Multiple containers: {stats['multiple_containers']}")
    print(f"Valid: {stats['valid']}")

    return results


def load_and_crop_image(image_path: str, bbox: dict, image_dir: str = None):
    """ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  bboxë¡œ í¬ë¡­

    Args:
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ (URL ë˜ëŠ” íŒŒì¼ëª…)
        bbox: Container bbox (x, y, width, height - percentage)
        image_dir: ë¡œì»¬ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬

    Returns:
        PIL.Image: í¬ë¡­ëœ ì´ë¯¸ì§€
    """
    # ì´ë¯¸ì§€ ë¡œë“œ
    if image_path.startswith('http'):
        response = requests.get(image_path)
        img = Image.open(BytesIO(response.content))
    else:
        if image_dir:
            full_path = Path(image_dir) / Path(image_path).name
        else:
            full_path = Path(image_path)

        if not full_path.exists():
            raise FileNotFoundError(f"Image not found: {full_path}")

        img = Image.open(full_path)

    # Label Studio bboxëŠ” percentageë¡œ ì €ì¥ë¨
    img_width, img_height = img.size
    x = int(bbox['x'] * img_width / 100)
    y = int(bbox['y'] * img_height / 100)
    width = int(bbox['width'] * img_width / 100)
    height = int(bbox['height'] * img_height / 100)

    # í¬ë¡­
    cropped = img.crop((x, y, x + width, y + height))
    return cropped


def create_classification_dataset(results, output_dir: str, task: str, image_dir: str = None):
    """ë¶„ë¥˜ ë°ì´í„°ì…‹ ìƒì„± (container ì˜ì—­ìœ¼ë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€)

    Args:
        results: íŒŒì‹±ëœ ê²°ê³¼
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        task: 'reusable' ë˜ëŠ” 'beverage'
        image_dir: ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
    """
    output_path = Path(output_dir)

    if task == 'reusable':
        label_field = 'container_type'
        classes = ['reusable', 'disposable', 'unclear']
    elif task == 'beverage':
        label_field = 'beverage_status'
        # Label Studioì˜ 'has_beverage' -> 'with_beverage', 'empty' -> 'empty' ë§¤í•‘
        label_mapping = {
            'has_beverage': 'with_beverage',
            'empty': 'empty',
            'unclear': 'unclear'
        }
        classes = ['with_beverage', 'empty', 'unclear']
    else:
        raise ValueError(f"Unknown task: {task}")

    # ë””ë ‰í† ë¦¬ ìƒì„±
    for class_name in classes:
        (output_path / task / class_name).mkdir(parents=True, exist_ok=True)

    stats = {c: 0 for c in classes}
    failed = []

    # ê° ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•˜ê³  ë¶„ë¥˜ë³„ë¡œ ì €ì¥
    for idx, item in enumerate(results):
        label = item['labels'].get(label_field)

        if not label:
            print(f"âš ï¸  Skipping {item['image']}: No {label_field} label")
            continue

        # Beverage taskì˜ ê²½ìš° ë¼ë²¨ ë§¤í•‘
        if task == 'beverage' and label in label_mapping:
            label = label_mapping[label]

        if label not in classes:
            print(f"âš ï¸  Skipping {item['image']}: Unknown label '{label}'")
            continue

        try:
            # Container ì˜ì—­ìœ¼ë¡œ í¬ë¡­
            cropped_img = load_and_crop_image(
                item['image_path'],
                item['container_bbox'],
                image_dir
            )

            # ì €ì¥
            dest_path = output_path / task / label / item['image']
            cropped_img.save(dest_path)

            stats[label] += 1
            if (idx + 1) % 10 == 0:
                print(f"Processed {idx + 1}/{len(results)} images...")

        except Exception as e:
            failed.append(item['image'])
            print(f"âŒ Failed to process {item['image']}: {e}")

    print(f"\n=== {task.upper()} Dataset Statistics ===")
    for class_name in classes:
        print(f"{class_name}: {stats[class_name]} images")
    print(f"Total: {sum(stats.values())} images")
    if failed:
        print(f"\nâš ï¸  Failed: {len(failed)} images")
        print(f"Failed images: {', '.join(failed[:10])}{' ...' if len(failed) > 10 else ''}")


def create_embedding_dataset(results, output_dir: str, image_dir: str = None):
    """ì„ë² ë”©ìš© ë°ì´í„°ì…‹ ìƒì„± (cup_codeë³„ë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ë¥˜)

    Args:
        results: íŒŒì‹±ëœ ê²°ê³¼
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        image_dir: ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
    """
    output_path = Path(output_dir)

    stats = {}
    failed = []
    skipped_no_cup_code = 0

    # ê° ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•˜ê³  cup_codeë³„ë¡œ ì €ì¥
    for idx, item in enumerate(results):
        cup_code = item['labels'].get('cup_code')

        if not cup_code:
            skipped_no_cup_code += 1
            continue

        # cup_code ë””ë ‰í† ë¦¬ ìƒì„±
        cup_dir = output_path / 'types' / cup_code
        cup_dir.mkdir(parents=True, exist_ok=True)

        if cup_code not in stats:
            stats[cup_code] = 0

        try:
            # Container ì˜ì—­ìœ¼ë¡œ í¬ë¡­
            cropped_img = load_and_crop_image(
                item['image_path'],
                item['container_bbox'],
                image_dir
            )

            # ì €ì¥
            dest_path = cup_dir / item['image']
            cropped_img.save(dest_path)

            stats[cup_code] += 1
            if (idx + 1) % 10 == 0:
                print(f"Processed {idx + 1}/{len(results)} images...")

        except Exception as e:
            failed.append(item['image'])
            print(f"âŒ Failed to process {item['image']}: {e}")

    print(f"\n=== EMBEDDING Dataset Statistics ===")
    for cup_code in sorted(stats.keys()):
        print(f"{cup_code}: {stats[cup_code]} images")
    print(f"Total: {sum(stats.values())} images")
    if skipped_no_cup_code > 0:
        print(f"Skipped (no cup_code): {skipped_no_cup_code} images")
    if failed:
        print(f"\nâš ï¸  Failed: {len(failed)} images")
        print(f"Failed images: {', '.join(failed[:10])}{' ...' if len(failed) > 10 else ''}")


def create_metadata_json(results, output_file: str):
    """ë©”íƒ€ë°ì´í„° JSON ìƒì„± (ì„ë² ë”© ì‹œìŠ¤í…œìš©)"""
    metadata = []

    for item in results:
        metadata.append({
            'image': item['image'],
            'cup_code': item['labels'].get('cup_code'),
            'container_type': item['labels'].get('container_type'),
            'beverage_status': item['labels'].get('beverage_status'),
            'lid_status': item['labels'].get('lid_status'),
            'quality': item['labels'].get('quality', []),
            'notes': item['labels'].get('notes', '')
        })

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    print(f"\nMetadata saved to: {output_file}")
    print(f"Total images: {len(metadata)}")


def create_cup_code_statistics(results, output_file: str):
    """ì»µ ì½”ë“œë³„ í†µê³„ ìƒì„±"""
    cup_code_stats = {}

    for item in results:
        cup_code = item['labels'].get('cup_code')
        if cup_code:
            if cup_code not in cup_code_stats:
                cup_code_stats[cup_code] = {
                    'count': 0,
                    'with_beverage': 0,
                    'empty': 0,
                    'unclear_beverage': 0,
                    'has_lid': 0,
                    'no_lid': 0,
                    'unclear_lid': 0
                }

            cup_code_stats[cup_code]['count'] += 1

            # ìŒë£Œ ìœ ë¬´ í†µê³„
            beverage_status = item['labels'].get('beverage_status')
            if beverage_status == 'has_beverage':
                cup_code_stats[cup_code]['with_beverage'] += 1
            elif beverage_status == 'empty':
                cup_code_stats[cup_code]['empty'] += 1
            elif beverage_status == 'unclear':
                cup_code_stats[cup_code]['unclear_beverage'] += 1

            # ëšœê»‘ ìœ ë¬´ í†µê³„
            lid_status = item['labels'].get('lid_status')
            if lid_status == 'has_lid':
                cup_code_stats[cup_code]['has_lid'] += 1
            elif lid_status == 'no_lid':
                cup_code_stats[cup_code]['no_lid'] += 1
            elif lid_status == 'unclear':
                cup_code_stats[cup_code]['unclear_lid'] += 1

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(cup_code_stats, f, indent=2, ensure_ascii=False)

    print(f"\nCup code statistics saved to: {output_file}")
    print("\n=== Cup Code Statistics ===")
    for cup_code, stats in sorted(cup_code_stats.items()):
        print(f"\n{cup_code}: {stats['count']} images")
        print(f"  Beverage: {stats['with_beverage']} with / {stats['empty']} empty / {stats['unclear_beverage']} unclear")
        print(f"  Lid: {stats['has_lid']} has / {stats['no_lid']} no / {stats['unclear_lid']} unclear")


def create_zip_archive(temp_dir: str, output_dir: str, output_filename: str, task: str, include_types: bool = False):
    """ì„ì‹œ ë””ë ‰í† ë¦¬ì˜ ë°ì´í„°ì…‹ì„ ZIP íŒŒì¼ë¡œ ì••ì¶•

    Args:
        temp_dir: ì„ì‹œ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        output_dir: ìµœì¢… ZIP íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
        output_filename: ZIP íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)
        task: 'reusable', 'beverage', ë˜ëŠ” 'both'
        include_types: types ë””ë ‰í† ë¦¬ í¬í•¨ ì—¬ë¶€

    Returns:
        str: ìƒì„±ëœ ZIP íŒŒì¼ ê²½ë¡œ
    """
    temp_path = Path(temp_dir)
    output_path = Path(output_dir)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ì••ì¶•í•  task ëª©ë¡ ê²°ì •
    tasks_to_zip = []
    if task in ['reusable', 'both']:
        tasks_to_zip.append('reusable')
    if task in ['beverage', 'both']:
        tasks_to_zip.append('beverage')

    # types ë””ë ‰í† ë¦¬ ì¶”ê°€
    if include_types and (temp_path / 'types').exists():
        tasks_to_zip.append('types')

    # ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬ë§Œ í•„í„°ë§
    existing_tasks = [t for t in tasks_to_zip if (temp_path / t).exists()]

    if not existing_tasks:
        return None

    # í•˜ë‚˜ì˜ ZIP íŒŒì¼ì— ëª¨ë“  ë°ì´í„°ì…‹ í¬í•¨
    zip_filename = output_filename if output_filename else f"dataset_{timestamp}.zip"
    zip_path = output_path / zip_filename

    print(f"\nCreating {zip_filename}...")

    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for task_name in existing_tasks:
            task_dir = temp_path / task_name

            # task_dir ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ZIPì— ì¶”ê°€
            for file_path in task_dir.rglob('*'):
                if file_path.is_file():
                    # ZIP ë‚´ë¶€ ê²½ë¡œë¥¼ task_name/class/filename í˜•ì‹ìœ¼ë¡œ
                    arcname = file_path.relative_to(temp_path)
                    zipf.write(file_path, arcname)

            print(f"  Added {task_name}/ directory")

    zip_size = zip_path.stat().st_size / (1024 * 1024)  # MB
    print(f"âœ… Created: {zip_path.name} ({zip_size:.2f} MB)")

    return str(zip_path)


def main():
    parser = argparse.ArgumentParser(
        description='Convert Label Studio annotations to training dataset (cropped by container bbox)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Create both reusable and beverage datasets as ZIP
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images

  # Include types/ directory for embeddings
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images --include-types

  # Specify output directory
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images --output-dir ./output

  # Specify output directory and file name
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images --output-dir ./output --output-file my_dataset.zip

  # Create only reusable dataset
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images --task reusable

  # Create only beverage dataset with types
  python convert_labelstudio_to_dataset.py export.json --image-dir ./images --task beverage --include-types

Output:
  dataset_YYYYMMDD_HHMMSS.zip (contains the following structure)
    reusable/
      reusable/       # Reusable container images (cropped)
      disposable/     # Disposable container images (cropped)
      unclear/        # Unclear container images (cropped)
    beverage/
      with_beverage/  # Container with beverage images (cropped)
      empty/          # Empty container images (cropped)
      unclear/        # Unclear beverage status images (cropped)
    types/            # Only if --include-types is used
      CUP001/         # Cup code based classification (for embeddings)
      CUP002/
      ...
        """
    )
    parser.add_argument('json_file', help='Label Studio export JSON file')
    parser.add_argument('--image-dir', required=True, help='Directory containing original images')
    parser.add_argument('--output-dir', default='.', help='Output directory for ZIP file (default: current directory)')
    parser.add_argument('--output-file', help='Output ZIP file name (default: dataset_YYYYMMDD_HHMMSS.zip)')
    parser.add_argument('--task', choices=['reusable', 'beverage', 'both'],
                       default='both', help='Which dataset to create (default: both)')
    parser.add_argument('--include-types', action='store_true',
                       help='Include types/ directory with cup_code-based classification for embeddings')

    args = parser.parse_args()

    # JSON íŒŒì‹±
    print(f"Parsing {args.json_file}...")
    results = parse_labelstudio_json(args.json_file, args.image_dir)

    if not results:
        print("\nâŒ No valid data found. Please check:")
        print("  1. All images have exactly one 'container' bbox annotation")
        print("  2. Annotations are properly labeled")
        return

    print(f"\nâœ… Found {len(results)} valid images with container bbox")

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)

        # ë°ì´í„°ì…‹ ìƒì„± (ì„ì‹œ ë””ë ‰í† ë¦¬ì—)
        if args.task in ['reusable', 'both']:
            print("\n" + "="*60)
            print("Creating Reusable/Disposable Classification Dataset")
            print("="*60)
            create_classification_dataset(results, temp_dir, 'reusable', args.image_dir)

        if args.task in ['beverage', 'both']:
            print("\n" + "="*60)
            print("Creating Beverage Status Classification Dataset")
            print("="*60)
            create_classification_dataset(results, temp_dir, 'beverage', args.image_dir)

        # ì„ë² ë”©ìš© ë°ì´í„°ì…‹ ìƒì„±
        if args.include_types:
            print("\n" + "="*60)
            print("Creating Embedding Dataset (Cup Code Classification)")
            print("="*60)
            create_embedding_dataset(results, temp_dir, args.image_dir)

        print("\n" + "="*60)
        print("Dataset creation complete!")
        print("="*60)
        print("\nDataset structure:")
        if args.task in ['reusable', 'both']:
            print(f"  reusable/")
            for class_name in ['reusable', 'disposable', 'unclear']:
                count = len(list((temp_path / 'reusable' / class_name).glob('*')))
                print(f"    {class_name}/  ({count} images)")
        if args.task in ['beverage', 'both']:
            print(f"  beverage/")
            for class_name in ['with_beverage', 'empty', 'unclear']:
                count = len(list((temp_path / 'beverage' / class_name).glob('*')))
                print(f"    {class_name}/  ({count} images)")
        if args.include_types and (temp_path / 'types').exists():
            print(f"  types/")
            cup_codes = sorted([d.name for d in (temp_path / 'types').iterdir() if d.is_dir()])
            for cup_code in cup_codes:
                count = len(list((temp_path / 'types' / cup_code).glob('*')))
                print(f"    {cup_code}/  ({count} images)")

        # ZIP íŒŒì¼ ìƒì„±
        print("\n" + "="*60)
        print("Creating ZIP archive...")
        print("="*60)

        zip_file = create_zip_archive(
            temp_dir,
            args.output_dir,
            args.output_file,
            args.task,
            args.include_types
        )

        if zip_file:
            print("\n" + "="*60)
            print("âœ… ZIP archive created!")
            print("="*60)
            print(f"  ğŸ“¦ {zip_file}")
        else:
            print("\nâš ï¸  No ZIP file created (no data to compress)")


if __name__ == '__main__':
    main()
